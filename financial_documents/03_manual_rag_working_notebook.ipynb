{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7774ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai neo4j langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7e2d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from neo4j import GraphDatabase\n",
    "from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# --- Azure OpenAI config ---\n",
    "API_KEY = \"CJf0VBRpakDXgiWW8wxUT7hL9CbaOmE979tyuEGMg0J5n5zsnWOOJQQJ99BGACYeBjFXJ3w3AAABACOGRVVR\"\n",
    "API_ENDPOINT = \"https://ameytxtai.openai.azure.com/\"\n",
    "API_VERSION = \"2023-12-01-preview\"\n",
    "DEPLOYMENT_NAME_LLM = \"test_jpm_3_5\"\n",
    "DEPLOYMENT_NAME_EMBED = \"text-embedding01\"\n",
    "\n",
    "# --- Neo4j config ---\n",
    "NEO4J_URI = \"neo4j+s://0e39a427.databases.neo4j.io\"\n",
    "NEO4J_USERNAME = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"5qAQp_sJS3DoW98Mx0X41PN91yKPqEtCzMagYYY3cdQ\"\n",
    "VECTOR_INDEX_NAME = \"chunkEmbeddings\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f8d1dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initialize drivers ---\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "\n",
    "embedder = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=DEPLOYMENT_NAME_EMBED,\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=API_ENDPOINT\n",
    ")\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=DEPLOYMENT_NAME_LLM,\n",
    "    openai_api_key=API_KEY,\n",
    "    azure_endpoint=API_ENDPOINT,\n",
    "    openai_api_version=API_VERSION,\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8237366b",
   "metadata": {},
   "source": [
    "## About Vector Search\n",
    "\n",
    "Vector search enables semantic retrieval of text chunks from your Neo4j graph.  \n",
    "Instead of keyword matching, it finds the most contextually similar passages to your query, even if the wording is different.\n",
    "\n",
    "**Tip:**  \n",
    "Inspect the returned results to verify relevance and adjust your chunking or embedding strategy if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366fcc8e",
   "metadata": {},
   "source": [
    "# Initialize Vector Retriever\n",
    "This section sets up the vector-based retriever for semantic search over your Neo4j knowledge graph.\n",
    "\n",
    "- **Query:**  \n",
    "  The example query asks, \"What are the risks that Apple faces?\"\n",
    "\n",
    "- **Vector Search in Neo4j:**  \n",
    "  - Connects to the Neo4j database using the provided `driver`.\n",
    "  - Uses the `chunkEmbeddings` vector index for efficient semantic retrieval.\n",
    "  - The `embedder` generates embeddings for the query.\n",
    "  - Returns the `text` property from matching chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20662c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorSearchNeo4j(query_vector):\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\n",
    "            f\"\"\"\n",
    "            CALL db.index.vector.queryNodes($index_name, 10, $query_vector)\n",
    "            YIELD node, score\n",
    "            RETURN node.text AS text, elementId(node) AS node_id, score\n",
    "            \"\"\",\n",
    "            index_name=VECTOR_INDEX_NAME,\n",
    "            query_vector=query_vector\n",
    "        )\n",
    "        records = result.data()\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    print(\"Retrieved Chunks:\")\n",
    "    node_ids = [record[\"node_id\"] for record in records]\n",
    "    return df, node_ids\n",
    "\n",
    "def getGraphRagResponse(query, node_ids, context_records):\n",
    "    with driver.session() as session:\n",
    "        for node_id in node_ids:\n",
    "            result = session.run(\n",
    "                query,\n",
    "                node_id=node_id\n",
    "            )\n",
    "            context_records.extend(result.data())\n",
    "\n",
    "    if len(context_records) == 0:\n",
    "        print(\"No enriched context found; falling back to plain chunk text.\")\n",
    "    else:\n",
    "        print(\"Enriched Context Records Found:\")\n",
    "        df_context = pd.DataFrame(context_records)\n",
    "\n",
    "    return context_records, df_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdbe66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the risks that Apple faces?\"\n",
    "\n",
    "response = llm([HumanMessage(content=query)])\n",
    "print(\"\\nPlain LLM Response:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7c25dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the risks that Apple faces?\"\n",
    "query_vector = embedder.embed_query(query)\n",
    "vector_search_apple_risks_df, node_ids_vector_search_apple_risk = vectorSearchNeo4j(query_vector)\n",
    "vector_search_apple_risks_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b500e0",
   "metadata": {},
   "source": [
    "## Advanced RAG: Contextual Cypher Retrieval\n",
    "\n",
    "This section demonstrates how to use a custom Cypher query with the `Vector Search` to provide richer, more contextual answers.\n",
    "\n",
    "- **Custom Cypher Query:**  \n",
    "  The `detail_context_query` matches text chunks (`node`) to their source documents, associated companies, and the risk factors those companies face.  \n",
    "  It returns:\n",
    "  - The company name\n",
    "  - The context text from the chunk\n",
    "  - A list of distinct risk factors\n",
    "\n",
    "- **Vector Search:**  \n",
    "  - Performs semantic search using the `chunkEmbeddings` vector index.\n",
    "  - Applies the custom Cypher query to retrieve relevant context and associated risk factors.\n",
    "\n",
    "- **GraphRAG:**  \n",
    "  - Combines the LLM and the custom retriever to answer the question:  \n",
    "    _\"What are the top risk factors that Apple faces?\"_\n",
    "\n",
    "- **Usage:**  \n",
    "  This approach enables highly specific, context-rich answers by leveraging the full power of graph relationships and semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068fb762",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_records_apple_risks = []\n",
    "detail_context_query  = \"\"\"\n",
    "                            MATCH (n) WHERE elementId(n) = $node_id\n",
    "                            MATCH (n)-[:FROM_DOCUMENT]-(doc:Document)-[:FILED]-(company:Company)-[:FACES_RISK]-(risk:RiskFactor)\n",
    "                            RETURN company.name AS company, n.text AS context, collect(DISTINCT risk.name) AS risks\n",
    "                        \"\"\"\n",
    "context_records_apple_risks, df_contextual_search_apple_risk = getGraphRagResponse(detail_context_query, node_ids_vector_search_apple_risk,context_records_apple_risks)\n",
    "\n",
    "df_contextual_search_apple_risk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ef0a2d",
   "metadata": {},
   "source": [
    "**Feed outputs of graph based traversals back to LLM**  \n",
    "  Get outputs from the graph by running multi hop queries as above, get it as a dataframe and then pass it back to the LLM to summarize the results to get a contextually rich response based on not just the documents but also the relationships in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a8fbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(context_records_apple_risks) > 0:\n",
    "    context_strings = []\n",
    "    for record in context_records_apple_risks:\n",
    "        risks = \", \".join(record.get(\"risks\", []))\n",
    "        company = record.get(\"company\", \"Unknown Company\")\n",
    "        context_text = record.get(\"context\", \"\")\n",
    "        context_strings.append(f\"Company: {company}\\nRisks: {risks}\\nContext: {context_text}\")\n",
    "\n",
    "    final_context = \"\\n\\n\".join(context_strings)\n",
    "else:\n",
    "    # fallback to plain text chunks if no enriched context\n",
    "    final_context = \"\\n\".join([r[\"text\"] for r in context_records_apple_risks])\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are a helpful assistant. Based on the following context, answer the question.\n",
    "Summarize in proper numbered bullet points, well spaced.\n",
    "Context:\n",
    "{final_context}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\"\"\"\n",
    "\n",
    "response = llm([HumanMessage(content=prompt)])\n",
    "print(\"\\nResponse from LLM:\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f49ae8",
   "metadata": {},
   "source": [
    "## Why \"Apple\" Queries Can Fail in Vector-Cypher Retrieval\n",
    "\n",
    "When you ask a question like \"What are the risks that Apple faces?\" using a vector-Cypher retriever, you may not get the structured or complete answer you expect. Here’s why:\n",
    "\n",
    "- **How Vector-Cypher Works:**  \n",
    "  - The retrieval process first performs a semantic search over all text chunks in the graph.\n",
    "  - It retrieves the top-k chunks most similar to your query—regardless of which company (or entity) they are about.\n",
    "  - The Cypher query then starts from each chunk and traverses the graph for related information.\n",
    "\n",
    "- **The Problem with Entity-Centric Queries:**  \n",
    "  - If your query is about \"Apple,\" but there are no chunks whose text is semantically similar to your query and also specifically about Apple, the retriever may return:\n",
    "    - Chunks about other companies.\n",
    "    - Chunks that mention \"risk\" but not \"Apple.\"\n",
    "    - Generic or boilerplate risk factor text.\n",
    "  - The Cypher query can only traverse from the retrieved chunk—it cannot \"filter\" or \"redirect\" to Apple if the chunk isn’t already about Apple.\n",
    "\n",
    "- **Key Limitation:**  \n",
    "  - **The chunk is the anchor.** If your query is about an entity (like Apple), but the chunk retrieval is not entity-aware, you may never reach the correct node or context in the graph.\n",
    "  - This is especially problematic for broad or entity-centric questions, where you want to aggregate or summarize information about a specific node (e.g., a company) rather than just retrieve semantically similar passages.\n",
    "\n",
    "> **Conclusion:**  \n",
    "> Vector-Cypher retrieval is powerful for finding relevant context, but it is fundamentally limited by the chunk-centric approach. For entity-centric questions, you need either:\n",
    "> - Chunks that are explicitly about the entity, or\n",
    "> - A retrieval/query strategy that starts from the entity node itself, not from arbitrary text chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a07468",
   "metadata": {},
   "source": [
    "## VectorCypherRetriever Example: Detailed Search with Context — Why This Is a Good Query\n",
    "\n",
    "This example demonstrates how to use `VectorCypherRetriever` to answer nuanced, relationship-driven questions by combining semantic search with graph traversal.\n",
    "\n",
    "**Why this is a good query:**\n",
    "\n",
    "- **Semantic Relevance:**  \n",
    "  The vector retriever surfaces text chunks that are semantically similar to the question (\"Who are the asset managers most affected by banking regulations?\"). This grounds the search in passages that actually discuss asset managers and regulations.\n",
    "\n",
    "- **Graph Contextualization:**  \n",
    "  The Cypher query starts from each relevant chunk and traverses the graph to:\n",
    "    - Find the source document.\n",
    "    - Identify the company associated with the document.\n",
    "    - Traverse to asset managers that own or are related to that company.\n",
    "\n",
    "- **Structured and Contextual Output:**  \n",
    "  The result provides:\n",
    "    - The company name (`company`)\n",
    "    - The asset manager’s name (`manager`)\n",
    "    - The text context from the original chunk (`context`)\n",
    "\n",
    "- **Why it works well:**  \n",
    "  - The question is naturally chunk-centric: you want to find meaningful passages about asset managers and regulations, then extract structured information about the entities involved.\n",
    "  - The graph traversal enriches the answer, linking unstructured context (text) to structured graph entities (companies, managers).\n",
    "  - This approach leverages the best of both worlds: semantic search for relevance, and graph queries for structure and relationships.\n",
    "\n",
    "**Summary:**  \n",
    "This pattern is ideal when your question is about relationships or context that can be surfaced from relevant passages, and when you want to return both the context and the structured entities connected to it.  \n",
    "It is less effective for purely entity-centric aggregation (like \"all risks for Apple\"), but perfect for questions where the chunk is the natural anchor for graph exploration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bd71cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_manager_query_text = \"Which Asset Managers are most affected by cryptocurrency policies?\"\n",
    "query_vector = embedder.embed_query(asset_manager_query_text)\n",
    "\n",
    "chunk_to_asset_manager_query = \"\"\"\n",
    " MATCH (n) WHERE elementId(n) = $node_id\n",
    " WITH n as node\n",
    "MATCH (node)-[:FROM_DOCUMENT]-(doc:Document)-[:FILED]-(company:Company)-[:OWNS]-(manager:AssetManager)\n",
    "RETURN company.name AS company, manager.managerName AS AssetManagerWithSharesInCompany, node.text AS context\n",
    "\"\"\"\n",
    "\n",
    "vector_search_asset_manager_df, node_ids_asset_manager = vectorSearchNeo4j(query_vector)\n",
    "vector_search_asset_manager_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32836d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_records_asset_manager = []\n",
    "context_records_asset_manager, df_contextual_search_asset_manager = getGraphRagResponse(chunk_to_asset_manager_query, node_ids_asset_manager,context_records_asset_manager)\n",
    "df_contextual_search_asset_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b74ad8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CYPHER_GENERATION_TEMPLATE = \"\"\"\n",
    "You are an expert Neo4j Cypher translator who understands natural language questions and generates Cypher queries strictly based on the Neo4j Schema provided.\n",
    "\n",
    "Instructions:\n",
    "- Use aliases for nodes and relationships.\n",
    "- Generate Cypher queries compatible with Neo4j 5.\n",
    "- Do not use EXISTS or SIZE.\n",
    "- Avoid LIMIT clauses.\n",
    "- Always use case-insensitive fuzzy matching for string properties (e.g., toLower(c.name) CONTAINS 'apple').\n",
    "- Use only nodes and relationships from this schema.\n",
    "\n",
    "Schema:\n",
    "{schema}\n",
    "\n",
    "Examples:\n",
    "\n",
    "Human: Find all companies owned by BlackRock Inc\n",
    "Assistant: ```MATCH (am:AssetManager)-[:OWNS]->(c:Company) WHERE toLower(am.managerName) CONTAINS 'blackrock inc' RETURN c.name```\n",
    "\n",
    "Human: List risk factors for Apple Inc\n",
    "Assistant: ```MATCH (c:Company)-[:FACES_RISK]->(r:RiskFactor) WHERE toLower(c.name) CONTAINS 'apple' RETURN r.name```\n",
    "\n",
    "Human: List documents mentioning Apple Inc and their associated risk factors\n",
    "Assistant: ```MATCH (c:Company)-[:FACES_RISK]->(r:RiskFactor)WHERE toLower(c.name) CONTAINS 'apple inc' WITH c,r MATCH (doc:Document)-[]-(c)  RETURN doc.id, collect(DISTINCT r.name) AS risks```\n",
    "\n",
    "Human: Find executives who are associated with companies that BlackRock Inc owns\n",
    "Assistant: ```MATCH (am:AssetManager)-[:OWNS]->(c:Company)<-[:HAS_ENTITY]-(e:Executive) WHERE toLower(am.managerName) CONTAINS 'blackrock inc' RETURN e.name, c.name```\n",
    "\n",
    "Human: Find transactions that mention products mentioned in documents filed by companies\n",
    "Assistant: ```MATCH (d:Document)-[:FILED]-(c:Company) MATCH (d)-[:MENTIONS]->(p:Product) MATCH (t:Transaction)-[:MENTIONS]->(p) RETURN DISTINCT c.name, t.name```\n",
    "\n",
    "Human: What metrics are Microsoft transactions associated with?\n",
    "Assistant: ```MATCH (c:Company)-[:MENTIONS]-(t:Transaction) WHERE toLower(c.name) CONTAINS 'microsoft' WITH t MATCH (t)-[:HAS_METRIC]->(m:FinancialMetric) RETURN DISTINCT m.name```\n",
    "\n",
    "Human: {question}\n",
    "Assistant:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd908160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "\n",
    "CYPHER_GENERATION_PROMPT = PromptTemplate(\n",
    "    input_variables=['schema','question'], validate_template=True, template=CYPHER_GENERATION_TEMPLATE\n",
    ")\n",
    "\n",
    "from langchain.graphs import Neo4jGraph\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=NEO4J_URI, \n",
    "    username=NEO4J_USERNAME, \n",
    "    password=NEO4J_PASSWORD,\n",
    "    database=\"neo4j\"\n",
    ")\n",
    "\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "    llm,\n",
    "    graph=graph,\n",
    "    cypher_prompt=CYPHER_GENERATION_PROMPT,\n",
    "    verbose=True,\n",
    "    allow_dangerous_requests=True,\n",
    "    return_direct=True,top_k=500\n",
    ")\n",
    "\n",
    "import json\n",
    "def chat(que):\n",
    "    r = chain.invoke(que)\n",
    "    print(r)\n",
    "    summary_prompt_tpl = f\"\"\"Context: {json.dumps(r['result'])}\n",
    "    * Summarise the above fact as if you are answering this question \"{r['query']}\"\n",
    "    * When the fact is not empty, assume the question is valid and the answer is true\n",
    "    * Do not return helpful or extra text or apologies\n",
    "    * List the results in rich text format if there are more than one results\n",
    "    * When you summarize, properly analyze ALL rows of data, if multiple year comparisons are asked, properly analyze and respond.\n",
    "    * DO NOT LIMIT THE NUMBER OF ROWS WHEN YOU SUMMARIZE\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    return llm.invoke(summary_prompt_tpl).content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91ae737",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r2 = chat(\"\"\"What metrics are Nvidia transactions associated with?\"\"\")\n",
    "print(f\"Final answer: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e6556e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90521be6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
